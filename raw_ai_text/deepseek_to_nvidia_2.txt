【封面报道】算力天花板的裂缝：DeepSeek冲击波下的英伟达变局

　　文｜财新周刊 冯奕铭（发自硅谷/北京）

　　引言：硅谷的“惊魂一夜”

　　2025年1月的圣克拉拉，原本应是科技巨头们在拉斯维加斯CES展会后休养生息的季节。然而，位于加州大道的英伟达（NVIDIA）总部“奋进号”（Endeavor）大楼内，几间会议室的灯火彻夜未熄。

　　打破平静的是来自大洋彼岸的一封“开源信”。北京时间1月下旬，中国人工智能实验室DeepSeek发布了其旗舰模型DeepSeek-V3。消息传回硅谷时正值深夜，但在Meta、Google以及OpenAI的开发者群组里，讨论热度瞬间爆表。一名不愿具名的硅谷大厂高级研究员向财新描述了当晚的情境：“原本大家都在按部就班地讨论下一代千亿级美元集群的基建方案，DeepSeek的技术报告像是一枚精确引导的深水炸弹，直接炸毁了‘算力即真理’的共识。”

　　次日美股开盘，尽管NVIDIA（NASDAQ：NVDA）股价起初表现平稳，但在私下的算力二级交易市场，H100、H800的现货租赁价格已出现阴跌。这场风暴的核心并不在于DeepSeek是否在性能上实现了绝对超越，而在于它揭示了一个令算力持有者感到不安的事实：通往AGI（通用人工智能）的门票，或许并不如想象中那么昂贵。

　　打破“算力迷信”

　　在过去两年的AI浪潮中，大模型竞赛被简化为一场关于“暴力美学”的军备竞赛。OpenAI首席执行官山姆·奥特曼（Sam Altman）曾公开谈论数万亿美元的芯片投资计划，其背后的逻辑基石是“缩放定律”（Scaling Laws）：参数规模越大，投入算力越多，模型能力越强。

　　DeepSeek-V3的出现，提供了一个极端的反例。其技术报告显示，这一拥有6710亿参数的旗舰模型，在约14.8万亿Token上完成预训练，仅消耗了约278.8万GPU小时。以市场公允价格核算，其总训练成本约为557.6万美元。

　　“这个数字在圈内引发了巨大的逻辑震荡。”一位接近监管层的科技政策分析人士对财新表示，“如果说GPT-4时代的训练成本是以‘亿’为单位，那么DeepSeek将这一门槛拉低到了‘百万’级别。这不仅仅是省钱，而是证明了算法架构（Architecture）对算力的杠杆效能，正处于一个质变的拐点。”

　　DeepSeek的核心武器是稀疏混合专家架构（Multi-head Latent Attention, MLA）与极致的通信优化。通过复杂的数学技巧，它显著减少了模型在推理和训练过程中的显存占用与计算开销。这意味着，在同等智能水平下，DeepSeek对NVIDIA高阶芯片的依赖度，远低于采用稠密架构（Dense Architecture）的西方同行。

　　这种效率革命，直接挑战了NVIDIA的高毛利叙事。2025财年，NVIDIA的毛利率维持在75%左右，其超额利润在很大程度上源于算力的稀缺性与大模型对硬件的低效消耗。一名资深芯片分析师指出：“如果所有模型公司都学会了DeepSeek这种‘精准手术’式的开发方式，那么过去那种‘大力出奇迹’的算力黑洞将不复存在。NVIDIA的GPU将从一种‘宗教仪式上的必需品’，回归为一种‘追求性价比的生产工具’。”

　　市场最初的逻辑是简单的溢价重估：如果模型能用十分之一的GPU训练出来，NVIDIA的销量是否会缩减九成？英伟达创始人黄仁勋在近期的闭门会议中显然在试图修正这种预期，他提出了“推理式智能”的新标签，试图证明虽然训练侧在“去泡沫化”，但应用端爆发带来的推理负载将填补空缺。

　　然而，这一逻辑在现实层面正遭遇挑战。财新调查发现，在国内外的算力中介市场，原本排队至半个季度后的H系列芯片订单，近期出现零星的退订或转租意向。一家总部位于新加坡的算力租赁商告诉财新：“客户的胃口变了。以前是‘有多少卡要多少卡’，现在是‘按DeepSeek的架构算，我只需要这么多卡’。这种精算师思维的介入，是过去两年从未有过的降温信号。”

    算力租赁商的“倒春寒”

　　“这种感觉就像是2000年互联网泡沫破裂前夕，大家还在讨论带宽，但突然发现网站不再需要那么多服务器了。”长期在香港和迪拜之间穿梭的高级算力掮客陈森（化名）对财新感慨。

　　陈森手中掌握着数百个H100及H800的节点资源。2024年上半年，他的手机几乎被初创公司的CTO和财务总监打爆，算力租金一度跳涨至每小时4.5美元以上，且必须半年预付。但进入2025年1月下旬，随着DeepSeek-V3架构细节的公开，这种“卖方市场”的铁律出现了松动。

　　财新从多位算力租赁中介处获悉，目前二级市场上NVIDIA H系列芯片的租赁指导价已较2024年底下调了12%—18%。更隐秘的变化发生在合约条款中：原本“不可撤销”的长约开始出现灵活变通的条款，部分算力中心甚至主动推出了针对MoE架构优化的“精简套餐”。

　　“DeepSeek效应”首先冲击的是那些原本计划通过“堆卡”来弥补算法平庸的企业。一名在新加坡经营算力池的运营商对财新分析称，DeepSeek证明了“算力冗余”不再是护城河，反而可能成为成本泥潭。由于DeepSeek开源了其底层的通信优化库，许多开发者发现，在相同硬件条件下，通过软件调优可以榨取比以往高出30%的性能。“这意味着原本需要1024张卡完成的微调任务，现在700张卡就能在同样的时间内跑完。剩下的300张卡，瞬间就成了市场的溢出供应。”

　　这一转变引发了资本市场的连锁反应。过去两年，全球范围内涌现出一批以GPU作为抵押物进行融资的“算力云”初创公司。其商业模式建立在GPU残值高、租赁需求刚性的假设之上。一旦租赁单价持续下滑，其资产负债表上的GPU残值重估将直接威胁到债务安全。

　　“我们现在最担心的不是订单减少，而是‘估值逻辑的反转’。”前述运营商表示。如果算力从一种“稀缺战略资产”退化为“标准化大宗商品”，那么支撑NVIDIA及整个算力产业链的高市盈率（PE）基础将不复存在。

　　与此同时，国内算力市场呈现出更为复杂的局面。受制于美国商务部不断加码的出口管制，高性能GPU在境内依然存在实质性的供应缺口。但DeepSeek的成功，给这种缺口蒙上了一层微妙的心理阴影。一位接近国内大型互联网公司的算力采购人士对财新表示：“过去我们对H20（NVIDIA针对中国市场的降级版芯片）表现出极大的焦虑，担心算力代差无法弥补。但现在管理层开始反思：如果通过算法优化能对冲30%甚至50%的硬件劣势，我们是否还有必要以极高的溢价在黑市去抢购那些合规风险极大的高阶芯片？”

　　这种“算法对冲硬件”的认知，正在悄然改变算力买家的决策权重。在2025年第一季度的采购季，多家中国科技巨头在内部评审中调高了“软件编译器效率”和“互联带宽利用率”的权重，而单纯的“单卡算力值”权重则有所下移。

　　“NVIDIA的卡依旧是最好的，但它不再是唯一的救命稻草。”陈森看着手中几份尚未签署的转租协议说，“现在的买家变得极其吝啬，他们不仅会查你的卡是多少年前的，还会问你的机房支不支持DeepSeek那种极致的并行通信方案。如果你跟不上这种效率革命，你的卡就是一堆废铁。”

第三章：黄仁勋的护城河迁移

　　面对算法效率革命对“暴力算力”叙事的瓦解，英伟达创始人黄仁勋展现出了极强的叙事修正能力。在2025年的一场内部高管会议上，黄仁勋反复提及一个词：“推理式智能”（Inference-time Intelligence）。

　　这不仅是一个技术术语，更是英伟达试图重塑资本信心的商业盾牌。在英伟达看来，如果DeepSeek证明了训练一个模型不再需要倾家荡产，那么省下来的钱绝不会回到股东的口袋，而是会被投入到更具规模、也更具粘性的推理环节中。

　　“训练定义了智能的上限，而推理决定了商业化的广度。”一位接近英伟达硅谷总部的资深架构师对财新解释称。他认为，DeepSeek-R1这类逻辑推理模型的崛起，实际上对硬件提出了另一种维度的挑战：模型不再是简单的“问答机”，而是在生成答案前进行数千次的自我修正与逻辑链推演。这种“思维链”（Chain of Thought）的爆发，对显存带宽（HBM）与芯片间互连速度（NVLink）的需求，甚至超过了传统的预训练。

　　英伟达的最新杀手锏Blackwell架构，正是这一转型下的产物。财新获取的一份技术对比资料显示，Blackwell在处理类似DeepSeek这种稀疏MoE架构时，其专门优化的FP8和FP4精度推理性能，最高可达上一代H100的30倍。英伟达试图通过这种近乎“代差式”的性能压制，告诉市场：即使算法变聪明了，你依然需要购买更贵、更高效的“整机系统”。

　　然而，护城河的稳固程度正受到CUDA生态“松动”的考验。长期以来，CUDA（计算统一设备架构）是英伟达锁死开发者的软绳。但DeepSeek的成功恰恰得益于其对底层算子的自主重写，它绕过了大量昂贵的CUDA标准库，转而使用更高效、更具通用性的底层语言进行优化。

　　“DeepSeek给行业示范了一种‘去CUDA化’的高级路径。”一位在北京中关村长期从事编译器开发的专家告诉财新，“当顶级算法团队有能力直接控制硬件底层时，英伟达那些封装好的软件套件就不再是必须品。这意味着，如果AMD或者其他国产芯片能在硬件性能上追平，软件不再是天劫。”

　　为了反击，英伟达正在从一家“卖芯片的公司”加速转型为一家“卖系统的公司”。其推出的GB200等整机柜方案，将计算、存储与网络高度集成，试图通过物理层面的“强耦合”来重新掌握定价权。

　　“黄仁勋正在玩一场双面游戏。”前述架构师分析道，“他一边支持DeepSeek这样的效率革命，因为它能让AI应用像电一样普及；另一边，他必须通过极其复杂的系统集成，确保即便智能变便宜了，英伟达依然是那个唯一的电力供应商。”

　　但华尔街的耐心正在经受考量。2025财年，英伟达的研发支出同比激增。在财报电话会上，分析师们关心的重点已经从“你能生产多少卡”转向了“你的毛利率何时会触顶”。当DeepSeek证明了“小而美”的可能性时，英伟达那种高度集成、高溢价的重资产模式，是否会成为AI时代的“过度工程”？

　　“英伟达最大的对手不是AMD，也不是DeepSeek，而是物理规律与经济学逻辑的交汇点。”一位常驻纽约的对冲基金经理对财新表示，“如果智能的边际成本下降速度快过英伟达产品的溢价速度，那么这场算力神话就将迎来终篇。”

第四章：戴着镣铐的突围

　　在深度学习的历史叙事中，资源匮乏往往被视为创新的死敌。但在中国算力市场，一种带有补偿性质的技术演进正在发生：既然无法在“卡的数量”上取胜，那就必须在“卡的效率”上登峰造极。

　　DeepSeek的横空出世，被业内视为一场典型的“极限生存压力下的技术突围”。一位接近DeepSeek核心团队的知情人士向财新透露，V3模型的研发背景正是由于美国商务部在2024年进一步收紧了高性能GPU的出口限制。当H100集群的获取变得极其困难且成本高昂时，团队不得不将研发重心转向如何“榨干”手中现有的、性能受限的H800，甚至是更低阶的H20芯片。

　　“这是一种被迫的‘优雅’。”该人士感叹。通过FP8混合精度训练和自研的HAI-LLM并行框架，DeepSeek证明了在算力代差面前，软件架构可以扮演“补丁”甚至“杠杆”的角色。这种路径在2025年的中国大模型圈内引发了强烈的共鸣：多家此前深陷“算力焦虑”的初创公司开始意识到，追逐上万张卡的万卡集群或许并非唯一的活路。

　　然而，这种突围也伴随着微妙的政策风险。2025年4月，美国政府一度对英伟达专为中国定制的H20芯片实施临时禁售，虽在三个月后予以恢复，但这段长达百日的“真空期”已彻底重塑了国内买家的心理预期。

　　“英伟达的中国特供版芯片正处于一种‘薛定谔的状态’。”一位资深国产GPU芯片创业者对财新表示。他观察到，国内头部的云厂商如阿里巴巴、百度、字节跳动，虽然在出口限制放宽后迅速补货H20，但私下里已将自研芯片和国产替代方案提升至战略红线。

　　财新调研发现，国产AI芯片在2025年上半年迎来了爆发式增长。寒武纪（688256.SH）在2025年一季度录得上市以来首次单季盈利，营收激增逾40倍；而华为昇腾（Ascend）系列则在政府主导的智算中心招标中拿下了近80%的市场份额。

　　“DeepSeek模式给国产芯片提供了一个完美的‘软着陆’样板。”前述芯片创业者分析称。过去，国产芯片最大的短板是CUDA生态缺失导致的运行低效，但如果行业整体转向类似DeepSeek这种“重算子优化、轻标准库依赖”的开发逻辑，国产芯片与英伟达之间的软件壁垒将被实质性削弱。

　　尽管如此，隐忧依然盘旋在曼哈顿和华盛顿的上空。2025年底，随着美国政府逐步释放放宽出口限制的信号，英伟达急于通过H20重夺被国产芯片侵蚀的市场。黄仁勋直言，中国市场蕴藏着500亿美元的机遇。但在中国开发者看来，这种“推拉效应”已经造成了不可逆的信任赤字。

　　“我们现在更像是在进行一场‘算力套利’。”一名驻扎在上海的AI实验室负责人对财新表示，“我们一边利用英伟达芯片的成熟生态快速迭代，一边把DeepSeek那种‘低算力需求’的基因刻进骨子里。这不仅仅是为了省钱，更是为了防止某一天，连H20这样的‘残血版’卡也会变成历史。”

　　这种“戴着镣铐跳舞”的姿态，构成了一幅奇特的行业图景：英伟达在为重返中国市场而焦虑，而中国的技术团队却在利用英伟达的对手——“算法效率”——来消解对英伟达的依赖。这场关于算力经济权的博弈，正从单纯的贸易壁垒演变为一场深刻的软件范式重构。

第五章：泡沫的灰犀牛

　　当“智能成本”以每年百倍的速度下坠时，资本市场原本紧绷的逻辑链条开始出现裂痕。

　　“如果DeepSeek证明了用500万美元就能买到两年前价值5亿美元的智能，那么此前那些融资数亿、甚至数十亿美元的通用大模型公司，其资产负债表上的‘估值’究竟还剩下多少？”一名长期跟踪AI领域的资深投行分析师向财新发问。他将这种现象称为“技术性通缩”带来的估值坍塌。

　　2025年下半年，这种担忧正在从二级市场的股价波动传导至一级市场的融资寒冬。财新统计显示，2025年前十个月，全球生成式AI领域的融资宗数同比减少了22%，尽管平均单笔融资金额因少数巨头（如OpenAI、Anthropic）的巨额续命而维持高位，但中后期的“独角兽”们正面临严峻的ROI（投资回报率）闭环挑战。

　　英伟达的市值在2025年10月曾触及历史高点，随后因DeepSeek引发的效率重估而剧烈震荡。2025财年第三季度财报显示，虽然英伟达数据中心收入依然高达512亿美元，但其毛利率增速已显著放缓。资本市场开始意识到：当DeepSeek让AI变得“无处不在”时，也让AI变得不再像以前那样“昂贵”。

　　“我们正处在一个极其矛盾的节点。”一位接近监管层的经济学家对财新分析。他认为，DeepSeek是AI普及的加速器，但也可能是算力泡沫的引信。“如果AI应用层迟迟不能产生规模化的、足以覆盖算力成本的利润流，那么当前的‘推理爆发’叙事，就只是在推迟泡沫破裂的时间。一旦云厂商发现扩建的数据中心无法收回成本，对英伟达的资本支出（CapEx）将面临断崖式削减。”

　　地缘政治的复杂性进一步放大了这种不确定性。2025年圣诞节前夕，英伟达以200亿美元溢价收购推理芯片领军者Groq，这一被戏称为“圣诞大收购”的动作，被外界解读为黄仁勋对GPU单一统治地位动摇的公开承认。黄仁勋试图通过此举告诉投资者：如果GPU不再是推理时代的最优解，英伟达就买下那个最优解。

　　然而，这种通过并购维持的霸权，能跑赢算法进化的速度吗？

　　“DeepSeek给全球AI产业上了一课：算力固然是护城河，但效率才是终极的绞肉机。”前述算力租赁商陈森在采访结束时，正准备处理掉手中最后一批H800的旧合约。他决定转向规模更小、更灵活的专用推理集群。

　　对于英伟达而言，DeepSeek带来的不是增长的终结，而是一场冷酷的定价权保卫战。在AI真正走向“工业化”的征途中，算力将不再是点石成金的魔法，而是如同钢铁与电力一般的工业底座。在这个低毛利、高竞争的未来里，英伟达必须证明，它不仅能卖出最贵的“铲子”，还能在金矿消失后，成为那个唯一能维持电网运行的人。

　　2025年的跨年钟声即将敲响，硅谷的咖啡馆里依然有人在彻夜讨论算法。只是这一次，人们讨论的不再是如何烧掉下一个十亿，而是如何用好手中的每一颗晶体管。泡沫的灰犀牛已隐约可见，而那些在算力丛林里戴着镣铐起舞的突围者，或许才是最先触碰到未来的。
